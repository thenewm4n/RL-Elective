{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/bpt85r9d2sx4bggpw3wbs6k00000gn/T/ipykernel_51927/115668758.py:50: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  desired_outputs_training[i, int(training_labels[training_indices[i]])] = 1\n",
      "/var/folders/jd/bpt85r9d2sx4bggpw3wbs6k00000gn/T/ipykernel_51927/115668758.py:54: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  desired_outputs_test[i, int(test_labels[test_indices[i]])] = 1\n"
     ]
    }
   ],
   "source": [
    "mnist = loadmat('MNIST.mat')\n",
    "\n",
    "# Read the train set\n",
    "training_samples = mnist['x_train']\n",
    "# Read the train labels\n",
    "training_labels = mnist['trainlabels']\n",
    "\n",
    "# Read the test set\n",
    "test_samples = mnist['x_test']\n",
    "# Read the test labels\n",
    "test_labels = mnist['testlabels']\n",
    "\n",
    "# We select only the data for three classes that we want to classify\n",
    "\n",
    "num_classes = 5   # Number of classes (i.e. numbers) we want to be able to classify\n",
    "\n",
    "training_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    \n",
    "    # Find the indexes of the training set corresponding to class i\n",
    "    training_index = np.where(training_labels == i)[0]\n",
    "    # Find the indexes of the test set corresponding to class i\n",
    "    test_index = np.where(test_labels == i)[0]\n",
    "    \n",
    "    # Append the training indexes in a list\n",
    "    training_indices.append(training_index)\n",
    "    # Append the testing indexes in a list\n",
    "    test_indices.append(test_index)\n",
    "\n",
    "# Reshape the lists to be a 1-d array (rather than lists of arrays, just one big array)\n",
    "training_indices = np.concatenate(training_indices, axis=0)\n",
    "test_indices = np.concatenate(test_indices, axis=0)\n",
    "\n",
    "# Create a training set and a test set with data belonging to the classes considered only\n",
    "training_samples = np.copy(training_samples[training_indices, :])\n",
    "test_samples = np.copy(test_samples[test_indices, :])\n",
    "\n",
    "# Compute the size of the train and test datasets\n",
    "training_size = np.shape(training_indices)[0]\n",
    "test_size = np.shape(test_indices)[0]\n",
    "\n",
    "# Create one-hot encoding labels for train and test datasets\n",
    "desired_outputs_training = np.zeros([training_size, num_classes])\n",
    "desired_outputs_test = np.zeros([test_size, num_classes])\n",
    "\n",
    "for i in range(training_size):\n",
    "\n",
    "    desired_outputs_training[i, int(training_labels[training_indices[i]])] = 1\n",
    "\n",
    "for i in range(test_size):\n",
    "\n",
    "    desired_outputs_test[i, int(test_labels[test_indices[i]])] = 1\n",
    "\n",
    "num_samples, img_size = training_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of image, take the transpose to see it in the right orientation\n",
    "example_image = np.reshape(training_samples[0], (28,28))\n",
    "plt.imshow(example_image.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 20\n",
    "num_batches = int(math.floor(num_samples / batch_size))\n",
    "\n",
    "# define the size of each of the layers in the network\n",
    "size_input_layer  = img_size\n",
    "size_hidden_layer = 100\n",
    "size_output_layer = num_classes\n",
    "\n",
    "# Add another hidden layer\n",
    "n_hidden_layer2 = 100 # number of neurons of the hidden layer. 0 deletes this layer\n",
    "\n",
    "# eta is the learning rate\n",
    "eta = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a simple network\n",
    "\n",
    "W1 = np.random.uniform(0, 1, (size_hidden_layer, size_input_layer))\n",
    "W2 = np.random.uniform(0, 1, (size_output_layer, size_hidden_layer))\n",
    "\n",
    "# The following normalises the random weights so that the sum of each row =1\n",
    "W1 = np.divide(W1, np.matlib.repmat(np.sum(W1, 1)[:, None], 1, size_input_layer))\n",
    "W2 = np.divide(W2, np.matlib.repmat(np.sum(W2, 1)[:, None], 1, size_hidden_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the biases\n",
    "biases_W1 = np.zeros((size_hidden_layer,))\n",
    "biases_W2 = np.zeros((size_output_layer,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of the network inputs and average error per epoch\n",
    "errors = np.zeros((num_epochs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, batch_size):\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Input (random element from the dataset)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     index \u001b[38;5;241m=\u001b[39m shuffled_indices[batch \u001b[38;5;241m*\u001b[39m batch_size \u001b[38;5;241m+\u001b[39m j]\n\u001b[0;32m---> 23\u001b[0m     x0 \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m[idx]\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Neural activation: input layer -> hidden layer\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     h1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W1,x0)\u001b[38;5;241m+\u001b[39mbias_W1\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "\n",
    "for i in range(0, num_epochs):\n",
    "\n",
    "    # We will shuffle the order of the samples each epoch\n",
    "    shuffled_indices = np.random.permutation(num_samples)\n",
    "    \n",
    "    for batch in range(0, num_batches):\n",
    "        \n",
    "        # Initialise the gradients for each batch\n",
    "        W1_gradient = np.zeros(W1.shape)\n",
    "        W2_gradient = np.zeros(W2.shape)\n",
    "\n",
    "        bias_W1_gradient = np.zeros(biases_W1.shape)\n",
    "        bias_W2_gradient = np.zeros(biases_W2.shape)\n",
    "        \n",
    "    \n",
    "        # Loop over all the samples in the batch\n",
    "        for j in range(0, batch_size):\n",
    "\n",
    "            # Input (random element from the dataset)\n",
    "            index = shuffled_indices[batch * batch_size + j]\n",
    "            activations_input = training_samples[index]\n",
    "            \n",
    "            # Neural activation: input layer -> hidden layer\n",
    "            weighted_sums_hidden = np.dot(W1, activations_input) + biases_W1\n",
    "\n",
    "            # Apply the sigmoid function\n",
    "            activations_hidden = 1 / (1 + np.exp(-weighted_sums_hidden))\n",
    "\n",
    "            # Neural activation: hidden layer -> output layer\n",
    "            weighted_sums_output = np.dot(W2, activations_hidden) + biases_W2\n",
    "\n",
    "            # Apply the sigmoid function\n",
    "            activations_output = 1 / (1 + np.exp(-weighted_sums_output))\n",
    "\n",
    "            # Form the desired output, the correct neuron should have 1 the rest 0\n",
    "            desired_output = desired_outputs_training[index]\n",
    "\n",
    "            # Compute the error signal\n",
    "            error = desired_output - activations_output\n",
    "\n",
    "            # Backpropagation: output layer -> hidden layer\n",
    "            delta_output = activations_output * (1 - activations_output) * error\n",
    "            W2_gradient += np.outer(delta_output, activations_hidden)\n",
    "\n",
    "            # Backpropagation: hidden layer -> input layer\n",
    "            delta_hidden = activations_hidden * (1 - activations_hidden) * np.dot(W2.T, delta_output)\n",
    "            W1_gradient += np.outer(delta_hidden, activations_input)\n",
    "\n",
    "            # Store the error per epoch (iterative mean update)\n",
    "            errors[i] = errors[i] + 0.5 * np.sum(np.square(error))/ num_samples\n",
    "\n",
    "        # After each batch update the weights using accumulated gradients\n",
    "        W2 += eta * dW2 / batch_size\n",
    "        W1 += eta * dW1 / batch_size\n",
    "        \n",
    "    print( \"Epoch \", i+1, \": error = \", errors[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
